# msfailab Configuration
#
# Copy to .env and edit as needed:
#   cp .env.example .env
#
# Docker Compose automatically loads .env from the project directory.
# See DEPLOYMENT.md for full deployment options including macOS support.

# =============================================================================
# Security Configuration (REQUIRED for production)
# =============================================================================

# Secret key for signing cookies and tokens.
# IMPORTANT: Generate a unique secret for any non-demo deployment!
# If you change this, all active sessions will be invalidated.
#
# Generate with: openssl rand -base64 48
#
# MSFAILAB_SECRET_KEY_BASE=your-64-byte-secret-here

# Public hostname for URL generation (WebSocket endpoints, redirects, etc.)
# Set this to your public domain when deploying behind a reverse proxy.
# MSFAILAB_HOST=localhost
# MSFAILAB_HOST=msfailab.example.com

# =============================================================================
# AI Backend Configuration (at least one required)
# =============================================================================

# Ollama - Local LLM server
# For containerized deployments, use host.docker.internal to reach host machine
# MSFAILAB_OLLAMA_HOST=http://localhost:11434
# MSFAILAB_OLLAMA_HOST=http://host.docker.internal:11434

# OpenAI
# MSFAILAB_OPENAI_API_KEY=sk-...

# Anthropic (Claude)
# MSFAILAB_ANTHROPIC_API_KEY=sk-ant-...

# =============================================================================
# Model Filtering (optional)
# =============================================================================
# Filter available models using glob patterns. Comma-separated for multiple.

# Ollama model filter (default: *)
# MSFAILAB_OLLAMA_MODEL_FILTER=*

# OpenAI model filter (default: gpt-5*)
# MSFAILAB_OPENAI_MODEL_FILTER=gpt-5*

# Anthropic model filter (default: claude-opus-4*,claude-sonnet-4*)
# MSFAILAB_ANTHROPIC_MODEL_FILTER=claude-opus-4*,claude-sonnet-4*

# Default model selection pattern (default: *)
# MSFAILAB_DEFAULT_MODEL=*

# Enable thinking mode for Ollama models that support it (default: true)
# MSFAILAB_OLLAMA_THINKING=true

# =============================================================================
# Server Configuration (optional)
# =============================================================================

# Port binding - format: [host:]port or host:port
# Default binds to localhost only for security
# MSFAILAB_PORT=127.0.0.1:4000
# MSFAILAB_PORT=0.0.0.0:4000    # Listen on all interfaces (use with caution)

# =============================================================================
# Docker Configuration (optional)
# =============================================================================

# Docker socket endpoint
# Linux/macOS Docker Desktop: /var/run/docker.sock (default)
# macOS Colima: ~/.colima/docker.sock
# Remote Docker: tcp://host:port
# MSFAILAB_DOCKER_ENDPOINT=/var/run/docker.sock

# Docker network for msfconsole containers
# Linux: "host" for full network functionality (default in Linux compose files)
# macOS: "msfailab" bridge network (default in macOS compose files)
# NOTE: This is automatically set by the compose files. Only override if needed.
# MSFAILAB_DOCKER_NETWORK=host
# MSFAILAB_DOCKER_NETWORK=msfailab

# Custom MSF console image (default: msfailab-msfconsole)
# Use this to run a custom image with your tools pre-installed
# MSFAILAB_DEFAULT_CONSOLE_IMAGE=msfailab-msfconsole
